{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_suja/base_unificada_suja.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\n",
    "    'data_evento'\n",
    "    , 'ano_evento'\n",
    "    , 'evento_MUNNOMEX'\n",
    "    , 'evento_SIGLA_UF'\n",
    "    , 'sum_CENTROBS'\n",
    "    , 'sum_QTINST34'\n",
    "    , 'sum_QTINST35'\n",
    "    , 'sum_QTINST36'\n",
    "    , 'sum_QTINST37'\n",
    "    , 'sum_QTLEIT34'\n",
    "    , 'sum_QTLEIT38'\n",
    "    , 'sum_QTLEIT39'\n",
    "    , 'sum_QTLEIT40'\n",
    "    , 'sum_CENTRNEO'\n",
    "    , 'TP_UNID_5'\n",
    "    , 'TP_UNID_7'\n",
    "    , 'TP_UNID_15'\n",
    "    , 'TP_UNID_36'\n",
    "    , 'FLAG_BASE'\n",
    "]\n",
    "df = df[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mes_ano_evento'] = [str(i)[0:7] for i in df['data_evento']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df.groupby(\n",
    " [\n",
    "    'evento_SIGLA_UF'\n",
    "    , 'evento_MUNNOMEX'\n",
    "    , 'ano_evento'\n",
    " ]\n",
    "    , as_index=False\n",
    ").agg(\n",
    "    QTINST34=pd.NamedAgg(column='sum_QTINST34', aggfunc='median')\n",
    "    , QTINST35=pd.NamedAgg(column='sum_QTINST35', aggfunc='median')\n",
    "    , QTINST36=pd.NamedAgg(column='sum_QTINST36', aggfunc='median')\n",
    "    , QTINST37=pd.NamedAgg(column='sum_QTINST37', aggfunc='median')\n",
    "    , QTLEIT34=pd.NamedAgg(column='sum_QTLEIT34', aggfunc='median')\n",
    "    , QTLEIT38=pd.NamedAgg(column='sum_QTLEIT38', aggfunc='median')\n",
    "    , QTLEIT39=pd.NamedAgg(column='sum_QTLEIT39', aggfunc='median')\n",
    "    , QTLEIT40=pd.NamedAgg(column='sum_QTLEIT40', aggfunc='median')\n",
    "    , TP_UNID_5=pd.NamedAgg(column='TP_UNID_5', aggfunc='median') \n",
    "    , TP_UNID_7=pd.NamedAgg(column='TP_UNID_7', aggfunc='median') \n",
    "    , TP_UNID_15=pd.NamedAgg(column='TP_UNID_15', aggfunc='median') \n",
    "    , TP_UNID_36=pd.NamedAgg(column='TP_UNID_36', aggfunc='median') \n",
    "    , QTD_NASCIMENTOS=pd.NamedAgg(column='data_evento', aggfunc='size') \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.to_csv('check_leitos_vs_nascimentos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = pd.read_csv('check_leitos_vs_nascimentos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['QTINST'] = df_agrupado['QTINST34'] + df_agrupado['QTINST35'] + df_agrupado['QTINST36'] + df_agrupado['QTINST37']\n",
    "df_agrupado['QTLEIT'] = df_agrupado['QTLEIT34'] + df_agrupado['QTLEIT38'] + df_agrupado['QTLEIT39'] + df_agrupado['QTLEIT40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação\n",
    "df_agrupado['var_QTD_NASCIMENTOS'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTD_NASCIMENTOS'].pct_change()\n",
    "\n",
    "df_agrupado['var_QTINST'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTINST'].pct_change()\n",
    "\n",
    "df_agrupado['var_QTLEIT'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTLEIT'].pct_change()\n",
    "\n",
    "df_agrupado['var_TP_UNID_5'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_5'].pct_change()\n",
    "\n",
    "df_agrupado['var_TP_UNID_7'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_7'].pct_change()\n",
    "\n",
    "df_agrupado['var_TP_UNID_15'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_15'].pct_change()\n",
    "\n",
    "df_agrupado['var_TP_UNID_36'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_36'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferença\n",
    "df_agrupado['dif_QTD_NASCIMENTOS'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTD_NASCIMENTOS'].diff()\n",
    "\n",
    "df_agrupado['dif_QTINST'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTINST'].diff()\n",
    "\n",
    "df_agrupado['dif_QTLEIT'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['QTLEIT'].diff()\n",
    "\n",
    "df_agrupado['dif_TP_UNID_5'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_5'].diff()\n",
    "\n",
    "df_agrupado['dif_TP_UNID_7'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_7'].diff()\n",
    "\n",
    "df_agrupado['dif_TP_UNID_15'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_15'].diff()\n",
    "\n",
    "df_agrupado['dif_TP_UNID_36'] = df_agrupado.sort_values(\n",
    "  by=['evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento']\n",
    ").groupby(\n",
    "  ['evento_SIGLA_UF', 'evento_MUNNOMEX']\n",
    ")['TP_UNID_36'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo os missings\n",
    "df_agrupado = df_agrupado.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando municípios que tiveram menos que 500 nascimentos em um ano\n",
    "df_agrupado['chave_mun_uf_evento'] = [f'{i}_{j}' for i, j in zip(df_agrupado['evento_SIGLA_UF'], df_agrupado['evento_MUNNOMEX'])]\n",
    "df_nasc_menor_500 = df_agrupado[df_agrupado['QTD_NASCIMENTOS'] <= 500]\n",
    "lista_mun_interesse = pd.unique(df_nasc_menor_500['chave_mun_uf_evento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4004 de um total de 4761\n",
    "df_interesse = df_agrupado[df_agrupado['chave_mun_uf_evento'].isin(lista_mun_interesse)]\n",
    "df_interesse = df_interesse.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\n",
    "    'evento_SIGLA_UF', 'evento_MUNNOMEX', 'ano_evento', 'QTINST', 'QTLEIT', 'TP_UNID_5', 'TP_UNID_7'\n",
    "    , 'TP_UNID_15', 'TP_UNID_36', 'QTD_NASCIMENTOS', 'var_QTINST', 'var_QTLEIT', 'var_TP_UNID_5'\n",
    "    , 'var_TP_UNID_7', 'var_TP_UNID_15', 'var_TP_UNID_36', 'var_QTD_NASCIMENTOS'\n",
    "]\n",
    "# Removendo os missings\n",
    "df_interesse = df_interesse[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as correlações todos os anos\n",
    "correlacoes = []\n",
    "ufs =  pd.unique(df_interesse['evento_SIGLA_UF'])\n",
    "# Agrupar os dados por município e calcular a correlação\n",
    "for uf in ufs:\n",
    "    subset = df_interesse.loc[(df_interesse['evento_SIGLA_UF'] == uf) & (df_interesse['ano_evento'] != 2018)]\n",
    "    if len(subset) > 1:  # Certifique-se de que há dados suficientes para calcular a correlação\n",
    "        correlacao_QTLEIT = subset[['var_QTLEIT', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_QTINST = subset[['var_QTINST', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_5 = subset[['var_TP_UNID_5', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_7 = subset[['var_TP_UNID_7', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_15 = subset[['var_TP_UNID_15', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_36 = subset[['var_TP_UNID_36', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacoes.append({'evento_SIGLA_UF': uf, 'correlacao_QTLEIT': correlacao_QTLEIT\n",
    "                           , 'correlacao_QTINST': correlacao_QTINST, 'correlacao_TP_UNID_5': correlacao_TP_UNID_5\n",
    "                           , 'correlacao_TP_UNID_7': correlacao_TP_UNID_7, 'correlacao_TP_UNID_15': correlacao_TP_UNID_15\n",
    "                           , 'correlacao_TP_UNID_36': correlacao_TP_UNID_36})\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_correlacoes = pd.DataFrame(correlacoes)\n",
    "aa=df_correlacoes[(df_correlacoes['correlacao_QTLEIT'] >= 0.5) | (df_correlacoes['correlacao_QTINST'] >= 0.5) |\n",
    "              (df_correlacoes['correlacao_TP_UNID_5'] >= 0.5) | (df_correlacoes['correlacao_TP_UNID_7'] >= 0.5) |\n",
    "              (df_correlacoes['correlacao_TP_UNID_15'] >= 0.5) | (df_correlacoes['correlacao_TP_UNID_36'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considerando variações positivas e negativas tenho somente uma uf que se observa euma forte correlação\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico\n",
    "# Criar gráficos de dispersão \n",
    "#for uf in aa['evento_SIGLA_UF']:\n",
    "#    subset = df_interesse[df_interesse['evento_SIGLA_UF'] == uf]\n",
    "#    corr = round(df_correlacoes.loc[df_correlacoes['evento_SIGLA_UF'] == uf, 'correlacao_QTLEIT'], 2)\n",
    "#    plt.figure(figsize=(10, 6))\n",
    "#    plt.scatter(subset['var_QTLEIT'], subset['var_QTD_NASCIMENTOS'], alpha=0.5)\n",
    "#    plt.title(f'Leitos VS Nasc corr {corr.reset_index(drop=True)[0]} municipio {uf} ')\n",
    "#    plt.xlabel('Número de Leitos (var_QTDLEIT)')\n",
    "#    plt.ylabel('Número de Nascimentos (var_qtd_nasc)')\n",
    "#    plt.grid(True)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as correlações todos os anos\n",
    "correlacoes_ano = []\n",
    "ufs =  pd.unique(df_interesse['evento_SIGLA_UF'])\n",
    "# Agrupar os dados por município e calcular a correlação\n",
    "for uf in ufs:\n",
    "    for ano in [2019, 2020, 2021, 2022]:\n",
    "        subset = df_interesse.loc[(df_interesse['evento_SIGLA_UF'] == uf) & (df_interesse['ano_evento'] == ano)]\n",
    "        if len(subset) > 1:  # Certifique-se de que há dados suficientes para calcular a correlação\n",
    "            correlacao_QTLEIT = subset[['var_QTLEIT', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_QTINST = subset[['var_QTINST', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_5 = subset[['var_TP_UNID_5', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_7 = subset[['var_TP_UNID_7', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_15 = subset[['var_TP_UNID_15', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_36 = subset[['var_TP_UNID_36', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacoes_ano.append({'evento_SIGLA_UF': uf, 'ano_evento': ano,'correlacao_QTLEIT': correlacao_QTLEIT\n",
    "                               , 'correlacao_QTINST': correlacao_QTINST, 'correlacao_TP_UNID_5': correlacao_TP_UNID_5\n",
    "                               , 'correlacao_TP_UNID_7': correlacao_TP_UNID_7, 'correlacao_TP_UNID_15': correlacao_TP_UNID_15\n",
    "                               , 'correlacao_TP_UNID_36': correlacao_TP_UNID_36})\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_correlacoes_ano = pd.DataFrame(correlacoes_ano)\n",
    "bb=df_correlacoes_ano[(df_correlacoes_ano['correlacao_QTLEIT'] >= 0.5) | (df_correlacoes_ano['correlacao_QTINST'] >= 0.5) |\n",
    "              (df_correlacoes_ano['correlacao_TP_UNID_5'] >= 0.5) | (df_correlacoes_ano['correlacao_TP_UNID_7'] >= 0.5) |\n",
    "              (df_correlacoes_ano['correlacao_TP_UNID_15'] >= 0.5) | (df_correlacoes_ano['correlacao_TP_UNID_36'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vou considerar somente as variações negativas\n",
    "# Lista para armazenar as correlações todos os anos\n",
    "correlacoes = []\n",
    "ufs =  pd.unique(df_interesse['evento_SIGLA_UF'])\n",
    "# Agrupar os dados por município e calcular a correlação\n",
    "for uf in ufs:\n",
    "    subset = df_interesse.loc[(df_interesse['evento_SIGLA_UF'] == uf) & (df_interesse['ano_evento'] != 2018) &\n",
    "                              (df_interesse['var_QTD_NASCIMENTOS'] < 0)]\n",
    "    if len(subset) > 1:  # Certifique-se de que há dados suficientes para calcular a correlação\n",
    "        correlacao_QTLEIT = subset[['var_QTLEIT', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_QTINST = subset[['var_QTINST', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_5 = subset[['var_TP_UNID_5', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_7 = subset[['var_TP_UNID_7', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_15 = subset[['var_TP_UNID_15', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacao_TP_UNID_36 = subset[['var_TP_UNID_36', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "        correlacoes.append({'evento_SIGLA_UF': uf, 'correlacao_QTLEIT': correlacao_QTLEIT\n",
    "                           , 'correlacao_QTINST': correlacao_QTINST, 'correlacao_TP_UNID_5': correlacao_TP_UNID_5\n",
    "                           , 'correlacao_TP_UNID_7': correlacao_TP_UNID_7, 'correlacao_TP_UNID_15': correlacao_TP_UNID_15\n",
    "                           , 'correlacao_TP_UNID_36': correlacao_TP_UNID_36})\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_correlacoes = pd.DataFrame(correlacoes)\n",
    "aa_=df_correlacoes[(df_correlacoes['correlacao_QTLEIT'] >= 0.5) | (df_correlacoes['correlacao_QTINST'] >= 0.5) |\n",
    "              (df_correlacoes['correlacao_TP_UNID_5'] >= 0.5) | (df_correlacoes['correlacao_TP_UNID_7'] >= 0.5) |\n",
    "              (df_correlacoes['correlacao_TP_UNID_15'] >= 0.5) | (df_correlacoes['correlacao_TP_UNID_36'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as correlações todos os anos e somente variacoes negativas\n",
    "correlacoes_ano = []\n",
    "ufs =  pd.unique(df_interesse['evento_SIGLA_UF'])\n",
    "# Agrupar os dados por município e calcular a correlação\n",
    "for uf in ufs:\n",
    "    for ano in [2019, 2020, 2021, 2022]:\n",
    "        subset = df_interesse.loc[(df_interesse['evento_SIGLA_UF'] == uf) & (df_interesse['ano_evento'] == ano) &\n",
    "                                 (df_interesse['var_QTD_NASCIMENTOS'] < 0)]\n",
    "        if len(subset) > 1:  # Certifique-se de que há dados suficientes para calcular a correlação\n",
    "            correlacao_QTLEIT = subset[['var_QTLEIT', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_QTINST = subset[['var_QTINST', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_5 = subset[['var_TP_UNID_5', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_7 = subset[['var_TP_UNID_7', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_15 = subset[['var_TP_UNID_15', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacao_TP_UNID_36 = subset[['var_TP_UNID_36', 'var_QTD_NASCIMENTOS']].corr().iloc[0, 1]\n",
    "            correlacoes_ano.append({'evento_SIGLA_UF': uf, 'ano_evento': ano,'correlacao_QTLEIT': correlacao_QTLEIT\n",
    "                               , 'correlacao_QTINST': correlacao_QTINST, 'correlacao_TP_UNID_5': correlacao_TP_UNID_5\n",
    "                               , 'correlacao_TP_UNID_7': correlacao_TP_UNID_7, 'correlacao_TP_UNID_15': correlacao_TP_UNID_15\n",
    "                               , 'correlacao_TP_UNID_36': correlacao_TP_UNID_36})\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_correlacoes_ano = pd.DataFrame(correlacoes_ano)\n",
    "bb_=df_correlacoes_ano[(df_correlacoes_ano['correlacao_QTLEIT'] >= 0.5) | (df_correlacoes_ano['correlacao_QTINST'] >= 0.5) |\n",
    "              (df_correlacoes_ano['correlacao_TP_UNID_5'] >= 0.5) | (df_correlacoes_ano['correlacao_TP_UNID_7'] >= 0.5) |\n",
    "              (df_correlacoes_ano['correlacao_TP_UNID_15'] >= 0.5) | (df_correlacoes_ano['correlacao_TP_UNID_36'] >= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variação entre municípios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a distância entre municipios selecionar os mais próximos dos municípios que tiveram queda e\n",
    "# verificar se tiveram aumento no número de nascimentos.\n",
    "base_lat_long_mun = pd.read_csv('base_limpa/latitude_longitude_municipios.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lat_long_mun['mun_uf'] = [f'{i}_{j}' for i, j in zip(base_lat_long_mun['mun_MUNNOMEX'], base_lat_long_mun['uf_SIGLA_UF'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5570"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(base_lat_long_mun['mun_uf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as UFs únicas\n",
    "ufs = pd.unique(base_lat_long_mun['uf_SIGLA_UF'])\n",
    "lista = []\n",
    "\n",
    "# Iterando por cada UF\n",
    "for uf in ufs:\n",
    "    df_uf = base_lat_long_mun[base_lat_long_mun['uf_SIGLA_UF'] == uf]\n",
    "    munic = pd.unique(df_uf['mun_uf']).tolist()\n",
    "    pares_processados = set()  # Usado para armazenar pares já processados\n",
    "    # Iterando por cada município\n",
    "    for i, mun in enumerate(munic):\n",
    "        for mun_2 in munic[i+1:]:\n",
    "            print(f'{uf} Municipio 1:{mun} Municipio 2 {mun_2}')\n",
    "            # Verificando se o par já foi processado\n",
    "            par = tuple(sorted([mun, mun_2]))\n",
    "            if par in pares_processados:\n",
    "                continue\n",
    "\n",
    "            # Coordenadas do primeiro município\n",
    "            lat1 =df_uf.loc[df_uf['mun_uf'] == mun, 'mun_LATITUDE'].values[0]\n",
    "            long1 = df_uf.loc[df_uf['mun_uf'] == mun, 'mun_LONGITUDE'].values[0]\n",
    "\n",
    "            # Coordenadas do segundo município\n",
    "            lat2 = df_uf.loc[df_uf['mun_uf'] == mun_2, 'mun_LATITUDE'].values[0]\n",
    "            long2 = df_uf.loc[df_uf['mun_uf'] == mun_2, 'mun_LONGITUDE'].values[0]\n",
    "\n",
    "            # Calculando a distância\n",
    "            distancia = geodesic((lat1, long1), (lat2, long2)).kilometers\n",
    "\n",
    "            # Criando o dicionário com os dados do par\n",
    "            dicionario = {\n",
    "                'municipio1':[mun], 'municipio2': [mun_2], 'dist_km': [distancia],\n",
    "                'lat_mun1': [lat1], 'long_mun1': [long1],\n",
    "                'lat_mun2': [lat2], 'long_mun2': [long2]\n",
    "            }\n",
    "            lista.append(dicionario)\n",
    "\n",
    "            # Adicionando o par ao conjunto de pares processados\n",
    "            pares_processados.add(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [pd.DataFrame(i) for i in lista]\n",
    "lista = pd.concat(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista.to_csv('distancia_municipios_uf_intra.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pares de  municipios vizinhos\n",
    "pares = [\n",
    "['AC', 'AM']\n",
    ",['AC', 'RO']\n",
    ",['AL', 'BA']\n",
    ",['AL', 'PE']\n",
    ",['AL', 'SE']\n",
    ",['AM', 'MT']\n",
    ",['AM', 'PA']\n",
    ",['AM', 'RO']\n",
    ",['AM', 'RR']\n",
    ",['AP', 'PA']\n",
    ",['BA', 'ES']\n",
    ",['BA', 'GO']\n",
    ",['BA', 'MG']\n",
    ",['BA', 'PE']\n",
    ",['BA', 'PI']\n",
    ",['BA', 'TO']\n",
    ",['CE', 'PB']\n",
    ",['CE', 'PE']\n",
    ",['CE', 'PI']\n",
    ",['CE', 'RN']\n",
    ",['DF', 'GO']\n",
    ",['DF', 'MG']\n",
    ",['ES', 'MG']\n",
    ",['ES', 'RJ']\n",
    ",['GO', 'MG']\n",
    ",['GO', 'MT']\n",
    ",['GO', 'MS']\n",
    ",['GO', 'TO']\n",
    ",['MA', 'PA']\n",
    ",['MA', 'PI']\n",
    ",['MA', 'TO']\n",
    ",['MG', 'MT']\n",
    ",['MG', 'RJ']\n",
    ",['MG', 'SP']\n",
    ",['MS', 'MT']\n",
    ",['MS', 'PR']\n",
    ",['MS', 'SP']\n",
    ",['MT', 'PA']\n",
    ",['MT', 'RO']\n",
    ",['MT', 'TO']\n",
    ",['PA', 'TO']\n",
    ",['PB', 'PE']\n",
    ",['PB', 'RN']\n",
    ",['PE', 'PI']\n",
    ",['PI', 'TO']\n",
    ",['PR', 'SC']\n",
    ",['PR', 'SP']\n",
    ",['RJ', 'SP']\n",
    ",['RS', 'SC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as UFs únicas\n",
    "lista_pares = []\n",
    "\n",
    "# Iterando por cada UF\n",
    "for par in pares:\n",
    "    df_uf1 = base_lat_long_mun[base_lat_long_mun['uf_SIGLA_UF'] == par[0]]\n",
    "    df_uf2 = base_lat_long_mun[base_lat_long_mun['uf_SIGLA_UF'] == par[1]]\n",
    "    munic1 = pd.unique(df_uf1['mun_uf']).tolist()\n",
    "    munic2 = pd.unique(df_uf2['mun_uf']).tolist()\n",
    "    pares_processados = set()  # Usado para armazenar pares já processados\n",
    "    # Iterando por cada município\n",
    "    for mun1 in munic1:\n",
    "        for mun2 in munic2:\n",
    "            print(f'Par {par} Municipio 1:{mun1} Municipio 2 {mun2}')\n",
    "            # Coordenadas do primeiro município\n",
    "            lat1 =df_uf1.loc[df_uf1['mun_uf'] == mun1, 'mun_LATITUDE'].values[0]\n",
    "            long1 = df_uf1.loc[df_uf1['mun_uf'] == mun1, 'mun_LONGITUDE'].values[0]\n",
    "\n",
    "            # Coordenadas do segundo município\n",
    "            lat2 = df_uf2.loc[df_uf2['mun_uf'] == mun2, 'mun_LATITUDE'].values[0]\n",
    "            long2 = df_uf2.loc[df_uf2['mun_uf'] == mun2, 'mun_LONGITUDE'].values[0]\n",
    "\n",
    "            # Calculando a distância\n",
    "            distancia = geodesic((lat1, long1), (lat2, long2)).kilometers\n",
    "\n",
    "            # Criando o dicionário com os dados do par\n",
    "            dicionario = {\n",
    "                'municipio1':[mun1], 'municipio2': [mun2], 'dist_km': [distancia],\n",
    "                'lat_mun1': [lat1], 'long_mun1': [long1],\n",
    "                'lat_mun2': [lat2], 'long_mun2': [long2]\n",
    "            }\n",
    "            lista_pares.append(dicionario)\n",
    "    lista_pares = [pd.DataFrame(i) for i in lista_pares]\n",
    "    lista_pares = pd.concat(lista_pares)\n",
    "    lista_pares.to_csv(f'./ufs_vizinhas/distancia_municipios_uf_vizinhos_{par[0]}_{par[1]}.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junta os arquivos das distâncias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = pd.read_csv('distancia_municipios_uf_v2.csv', sep=';', decimal=',')\n",
    "munic1 = lista['municipio2']\n",
    "munic2 = lista['municipio1']\n",
    "lista2 = lista\n",
    "lista2['municipio1']=munic2\n",
    "lista2['municipio2']=munic1\n",
    "lista = pd.concat([lista, lista2]).reset_index(drop=True)\n",
    "# selecionando somente municípios com até 100 km de distância\n",
    "lista_100 = lista[lista['dist_km'] <= 100.99].sort_values(['municipio1', 'dist_km']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacoes_negativas = df_agrupado.loc[(df_agrupado['ano_evento'] != 2018) &\n",
    "                              (df_agrupado['var_QTD_NASCIMENTOS'] < 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variacoes_positivas = df_agrupado.loc[(df_agrupado['ano_evento'] != 2018) &\n",
    "#                                      (df_agrupado['var_QTD_NASCIMENTOS'] > 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vou pegar a chave\n",
    "chave_uf_mun = pd.unique(variacoes_negativas['chave_mun_uf_evento'])\n",
    "colunas = [\n",
    "    'chave_mun_uf_evento'\n",
    "    , 'ano_evento'\n",
    "    , 'QTD_NASCIMENTOS'\n",
    "    , 'var_QTD_NASCIMENTOS'\n",
    "    , 'dif_QTD_NASCIMENTOS'\n",
    "]\n",
    "for munic in chave_uf_mun:\n",
    "    muncipio_transf = lista_100.loc[lista_100['municipio1']==munic, 'municipio2']\n",
    "    df_perde = df_agrupado.loc[(df_agrupado['ano_evento'] != 2018) &\n",
    "                             (df_agrupado'chave_mun_uf_evento'] == munic), colunas].reset_index(drop=True)\n",
    "    df_ganha = df_agrupado.loc[(df_agrupado['ano_evento'] != 2018) &\n",
    "                             (df_agrupado'chave_mun_uf_evento'].isin(muncipio_transf)), colunas].reset_index(drop=True)\n",
    "    df_ganha.columns = [f'compara_{i}' for i in df_ganha.columns]\n",
    "    df_perde = df_perde.merge(df_ganha, how='left', left_on='ano_evento', right_on='compara_ano_evento')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular os deltas e depois fazer a correlação entre os municipios para variação e diferença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacoes_positivas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacoes_negativas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacoes_negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
