{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Funcoes_auxiliares.func_aux import *\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowing the dataset\n",
    "At first, no cleaning will be applied to the dataset, later we will apply all cleaning and make a new EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5c667751b380>:2: DtypeWarning: Columns (25,26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('base_suja/base_unificada_suja.csv')\n"
     ]
    }
   ],
   "source": [
    "#Import dataset\n",
    "df = pd.read_csv('base_suja/base_unificada_suja.csv')\n",
    "variaveis = [\n",
    "    'data_evento', 'ano_evento', 'TIPOBITO', 'evento_MUNNOMEX',\n",
    "    'res_MUNNOMEX', 'evento_CAPITAL', 'res_CAPITAL', 'evento_REGIAO',\n",
    "    'res_REGIAO', 'evento_SIGLA_UF', 'res_SIGLA_UF', 'IDADEMAE',\n",
    "    'idademae_faixa', 'ESCMAE2010', 'escolaridade_mae', 'OBITOGRAV',\n",
    "    'GRAVIDEZ', 'tipo_gravidez', 'SEMAGESTAC', 'idade_gestacao_faixa',\n",
    "    'SEXO', 'def_sexo', 'PESO', 'peso_faixa', 'OBITOPARTO',\n",
    "    'def_obito_parto', 'CAUSABAS', 'causabas_capitulo',\n",
    "    'causabas_categoria', 'causabas_grupo', 'causabas_subcategoria',\n",
    "    'FLAG_BASE', 'sum_CENTROBS', 'sum_QTINST34', 'sum_QTINST35',\n",
    "    'sum_QTINST36', 'sum_QTINST37', 'sum_QTLEIT34', 'sum_QTLEIT38',\n",
    "    'sum_QTLEIT39', 'sum_QTLEIT40', 'sum_CENTRNEO','TP_UNID_5', 'TP_UNID_7',\n",
    "    'TP_UNID_15', 'TP_UNID_36', 'TP_UNID_61'\n",
    "]\n",
    "df = df[variaveis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration to show more rows and columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dicionario = 'https://docs.google.com/spreadsheets/d/1QFy_F2o81ULglNx8knNqg6oI7v3RARaUAaLLwOQr7K4/edit?usp=sharing'\n",
    "f\"\"\"The dataset has {len(df)} lines and {len(df.columns)} columns. More details can be consulted in the dictionary {url_dicionario}. Below the type of variables and the 'face' from the dataset\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Checking data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate data \n",
    "duplicados = df.duplicated()\n",
    "soma = duplicados.sum()\n",
    "f\"\"\"The dataset has {soma} duplicate rows, which represents {round((soma/len(df)) * 100, 2)} %\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of duplicates by FLAG_BASE, res_SIGLA_UF and ano_evento\n",
    "df_duplicados = df[duplicados]\n",
    "df_duplicados.value_counts(['FLAG_BASE', 'ano_evento', 'res_SIGLA_UF'])\n",
    "\n",
    "# There is no concentration of missing items that indicates a structural problem with filling in the data, whether by year or \n",
    "# UF of residence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counting missing values\n",
    "df_sim_dofet = df[df['FLAG_BASE']=='SIM_DOFET']\n",
    "missing_count_sim_dofet = df_sim_dofet.isnull().sum()  # counts the null values in each column\n",
    "missing_percent_sim_dofet = round((missing_count_sim_dofet / len(df_sim_dofet)) * 100,2)  # calculates the percentage of null values\n",
    "missing_data_sim_dofet = pd.DataFrame({'Missing Count': missing_count_sim_dofet, 'Missing Percentage': missing_percent_sim_dofet})\n",
    "missing_data_sim_dofet.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "missing_data_sim_dofet.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "missing_data_sim_dofet['BASE'] = 'SIM_DOFET'\n",
    "\n",
    "df_sinasc = df[df['FLAG_BASE']=='SINASC']\n",
    "missing_count_sinasc = df_sinasc.isnull().sum()  # counts the null values in each column\n",
    "missing_percent_sinasc = round((missing_count_sinasc / len(df_sinasc)) * 100,2)  # calculates the percentage of null values\n",
    "missing_data_sinasc = pd.DataFrame({'Missing Count': missing_count_sinasc, 'Missing Percentage': missing_percent_sinasc})\n",
    "missing_data_sinasc.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "missing_data_sinasc.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "missing_data_sinasc['BASE'] = 'SINASC'\n",
    "\n",
    "# appending\n",
    "missing_data = pd.concat([missing_data_sim_dofet, missing_data_sinasc])\n",
    "\n",
    "# Sorting the DataFrame by the highest missing frequencies\n",
    "missing_data_sorted = missing_data.sort_values(by=['BASE', 'Missing Count'], ascending=False)\n",
    "\n",
    "missing_data_sorted[missing_data_sorted['Missing Percentage'] > 0]\n",
    "\n",
    "# Some variables are not filled in the sinasc dataset. For EDA it will be used in SIM_DOFET, but in the model it will not be removed\n",
    "# 'OBITOGRAV' no padding at the base\n",
    "# Missing points for other variables will be removed, keeping the variables in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del missing_data_sorted, missing_data, df_sim_dofet, df_sinasc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is any pattern in the missing data looking at year and 'res_SIGLA_UF'\n",
    "lista = ['ESCMAE2010', 'SEMAGESTAC', 'PESO', 'IDADEMAE']\n",
    "for i in lista:\n",
    "    print(f\"\"\"Variável {i}\\n\\n{df.loc[df[i].isnull(), ['FLAG_BASE', 'ano_evento', 'res_SIGLA_UF']].value_counts()}\"\"\")\n",
    "\n",
    "# Some UF's have very high values, but compared to the total UF it is less than 10%\n",
    "# len(df.loc[(df['res_SIGLA_UF']=='CE') & (df['ano_evento']==2021) & (df['FLAG_BASE']=='SINASC')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ignorado = df.loc[(df['ESCMAE2010']==9) | (df['GRAVIDEZ']==9) |\n",
    "                     (df['idade_gestacao_faixa']=='Ignorado') | (df['SEXO']==0)]\n",
    "df_ignorado['FLAG_BASE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_cat = [\n",
    "'ano_evento'\n",
    ", 'TIPOBITO'       \n",
    ", 'evento_MUNNOMEX'\n",
    ", 'res_MUNNOMEX'\n",
    ", 'evento_CAPITAL'\n",
    ", 'res_CAPITAL'\n",
    ", 'evento_REGIAO'\n",
    ", 'res_REGIAO'\n",
    ", 'evento_SIGLA_UF'\n",
    ", 'res_SIGLA_UF'\n",
    ", 'idademae_faixa'\n",
    ", 'ESCMAE2010'\n",
    ", 'escolaridade_mae'\n",
    ", 'OBITOGRAV'\n",
    ", 'GRAVIDEZ'\n",
    ", 'tipo_gravidez'\n",
    ", 'idade_gestacao_faixa'\n",
    ", 'SEXO'\n",
    ", 'def_sexo'\n",
    ", 'peso_faixa'\n",
    ", 'OBITOPARTO'\n",
    ", 'def_obito_parto'\n",
    ", 'CAUSABAS'\n",
    ", 'causabas_capitulo'\n",
    ", 'causabas_categoria'\n",
    ", 'causabas_grupo'\n",
    ", 'causabas_subcategoria'\n",
    ", 'FLAG_BASE'\n",
    "            ]\n",
    "for col in lista_cat:\n",
    "    print(f'\\nPercentual de valores únicos para {col}:')\n",
    "    print(round((df[col].value_counts()/len(df)) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics for Numeric Variables\n",
    "lista_numerica = [\n",
    "'IDADEMAE'\n",
    ", 'SEMAGESTAC'\n",
    ", 'PESO'\n",
    ", 'sum_CENTROBS'\n",
    ", 'sum_QTINST34'\n",
    ", 'sum_QTINST35'\n",
    ", 'sum_QTINST36'\n",
    ", 'sum_QTINST37'\n",
    ", 'sum_QTLEIT34'\n",
    ", 'sum_QTLEIT38'\n",
    ", 'sum_QTLEIT39'\n",
    ", 'sum_QTLEIT40'\n",
    ", 'sum_CENTRNEO'\n",
    ", 'TP_UNID_5'\n",
    ", 'TP_UNID_7'\n",
    ", 'TP_UNID_15'\n",
    ", 'TP_UNID_36'\n",
    ", 'TP_UNID_61'\n",
    "]\n",
    "estatisticas_numericas = df[lista_numerica].describe()\n",
    "estatisticas_numericas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers(col):\n",
    "    q1 = col.quantile(0.25)\n",
    "    q3 = col.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = col[(col < lower_bound) | (col > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "outliers_numericos = df[lista_numerica].apply(detectar_outliers)\n",
    "\n",
    "for i in lista_numerica:\n",
    "    print(outliers_numericos.loc[~outliers_numericos[i].isna(), [i]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lista_numerica:\n",
    "    x1 = df.loc[df['ano_evento'] == 2019, i]\n",
    "    x2 = df.loc[df['ano_evento'] == 2020, i]\n",
    "    x3 = df.loc[df['ano_evento'] == 2021, i]\n",
    "    x4 = df.loc[df['ano_evento'] == 2022, i]\n",
    "\n",
    "    # Normalize\n",
    "    kwargs = dict(alpha=0.5, bins=100, density=True, stacked=True)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()  # Creates a new figure for each iteration\n",
    "    plt.hist(x1, **kwargs, color='g', label='2019')\n",
    "    plt.hist(x2, **kwargs, color='b', label='2020')\n",
    "    plt.hist(x3, **kwargs, color='r', label='2021')\n",
    "    plt.hist(x4, **kwargs, color='y', label='2022')\n",
    "    plt.gca().set(title=f'Histograma {i}', ylabel='Probability')\n",
    "    # plt.xlim(50, 75)\n",
    "    plt.legend()\n",
    "\n",
    "    # Show or save the figure here if needed\n",
    "    # plt.savefig(f'histograma_{i}.png')\n",
    "\n",
    "    plt.show()  # Show the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause of death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(index=df['CAUSABAS'], columns=df['ano_evento'])#, normalize='index')\n",
    "contingency_table = contingency_table.reset_index()\n",
    "contingency_table.loc[contingency_table['CAUSABAS'].isin(['P200', 'P95'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Births by municipality per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc = df.loc[df['FLAG_BASE']=='SINASC']\n",
    "pd.crosstab(index=df_sinasc['evento_MUNNOMEX'], columns=df_sinasc['ano_evento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and input data missing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input base SIM_DOFET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_input = ['ano_evento','res_REGIAO', 'evento_REGIAO', 'IDADEMAE', 'escolaridade_mae', 'tipo_gravidez'\n",
    "             , 'SEMAGESTAC', 'SEXO', 'PESO']\n",
    "df_sim = df.loc[df['FLAG_BASE']=='SIM_DOFET']\n",
    "df_sim_dofet = df_sim[var_input]\n",
    "df_sim_dofet = df_sim_dofet.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando missings em Ignorados\n",
    "# Substituir 'Ignorado' por NaN nas variáveis categóricas especificadas\n",
    "df_sim_dofet[\n",
    "    [\n",
    "         'escolaridade_mae'\n",
    "         , 'tipo_gravidez'\n",
    "    ]\n",
    "] = df_sim_dofet[\n",
    "    [\n",
    "         'escolaridade_mae'\n",
    "        , 'tipo_gravidez'\n",
    "    ]\n",
    "].replace('Ignorado', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_dofet.loc[\n",
    "    (df_sim_dofet['IDADEMAE'] < 10) | (df_sim_dofet['IDADEMAE'] > 50) , 'IDADEMAE'\n",
    "] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_dofet.loc[\n",
    "    (df_sim_dofet['SEMAGESTAC'] > 42) , 'SEMAGESTAC'\n",
    "] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo NaN em PESO\n",
    "# Calcular os limites inferiores e superiores para PESO\n",
    "std_peso = np.std(df['PESO'])\n",
    "media_peso = np.mean(df['PESO'])\n",
    "lim_inf = media_peso - (6 * std_peso)\n",
    "lim_sup = media_peso + (6 * std_peso)\n",
    "\n",
    "# Substituir valores fora do intervalo especificado por NaN na variável 'PESO'\n",
    "df_sim_dofet.loc[\n",
    "    (df_sim_dofet['PESO'] <= 0) | (df_sim_dofet['PESO'] < lim_inf) | (df_sim_dofet['PESO'] > lim_sup), 'PESO'\n",
    "] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim_dofet.loc[df_sim_dofet['SEXO'] == 0, 'SEXO'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando os Missings em cada coluna\n",
    "df_sim_dofet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter variáveis categóricas para numéricas temporariamente\n",
    "df_sim_dofet_encoded = pd.get_dummies(\n",
    "    df_sim_dofet, columns=[\n",
    "        'ano_evento'\n",
    "        , 'res_REGIAO'\n",
    "        , 'evento_REGIAO'\n",
    "        , 'escolaridade_mae'\n",
    "        , 'tipo_gravidez'\n",
    "        , 'SEXO'\n",
    "    ]\n",
    "    , drop_first=False\n",
    ")\n",
    "\n",
    "# Imputação usando KNN\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_imputed_array = knn_imputer.fit_transform(df_sim_dofet_encoded)\n",
    "df_imputed = pd.DataFrame(df_imputed_array, columns=df_sim_dofet_encoded.columns)\n",
    "\n",
    "# Reverter a codificação dummy para categorias originais mantendo os nomes originais\n",
    "for col in ['ano_evento', 'res_REGIAO', 'evento_REGIAO', 'escolaridade_mae', 'tipo_gravidez', 'SEXO']:\n",
    "    dummy_cols = [c for c in df_imputed.columns if c.startswith(col + '_')]\n",
    "    df_imputed[col] = df_imputed[dummy_cols].idxmax(axis=1).apply(lambda x: x[len(col) + 1:])\n",
    "    df_imputed.drop(dummy_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = df_sim.reset_index(drop=True)\n",
    "df_imputed = df_imputed.reset_index(drop=True)\n",
    "df_sim['ano_evento'] = df_imputed['ano_evento']\n",
    "df_sim['res_REGIAO'] = df_imputed['res_REGIAO']\n",
    "df_sim['evento_REGIAO'] = df_imputed['evento_REGIAO']\n",
    "df_sim['IDADEMAE'] = df_imputed['IDADEMAE']\n",
    "df_sim['escolaridade_mae'] = df_imputed['escolaridade_mae']\n",
    "df_sim['tipo_gravidez'] = df_imputed['tipo_gravidez']\n",
    "df_sim['SEMAGESTAC'] = df_imputed['SEMAGESTAC']\n",
    "df_sim['SEXO'] = df_imputed['SEXO']\n",
    "df_sim['PESO'] = df_imputed['PESO']\n",
    "df_sim['SEXO'] = df_sim['SEXO'].astype(float)\n",
    "df_sim['SEXO'] = df_sim['SEXO'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserir pós input\n",
    "df_sim['def_sexo'] = np.where(df_sim['SEXO']==1, 'Masculino', 'Feminino')\n",
    "df_sim['idade_gestacao_faixa'] = [func_categorize_idade_gest(int(round(i,0))) for i in df_sim['SEMAGESTAC']]\n",
    "df_sim['idademae_faixa'] = [func_categorize_idademae(int(round(i, 0))) for i in df_sim['IDADEMAE']]\n",
    "df_sim['peso_faixa'] = [func_categorize_peso(round(i,0)) for i in df_sim['PESO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df_sim['FLAG_BASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apendando as bases\n",
    "df = df.loc[df['FLAG_BASE']=='SINASC']\n",
    "df = pd.concat([df, df_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['FLAG_BASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['FLAG_BASE'] == 'SIM_DOFET'].value_counts(['ano_evento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns with a high frequency of missings\n",
    "\n",
    "#df_limpo = df_limpo.drop(columns=['OBITOGRAV', 'causabas_categoria', 'TIPOBITO', 'causabas_capitulo', 'CAUSABAS'\n",
    "#                                  , 'def_obito_parto', 'OBITOPARTO', 'causabas_subcategoria', 'causabas_grupo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates SINASC\n",
    "tam_inicial = len(df)\n",
    "df_sinasc = df.loc[df['FLAG_BASE']=='SINASC']\n",
    "df_sim =  df.loc[df['FLAG_BASE']=='SIM_DOFET']\n",
    "df_limpo = df_sinasc.drop_duplicates()\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove duplicates {tam_inicial - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo os missing SINASC\n",
    "\n",
    "#lista_missing_sim = [\n",
    "#   'sum_CENTROBS','sum_QTINST34','sum_QTINST35','sum_QTINST36','sum_QTINST37','TP_UNID_5'\n",
    "#    ,'TP_UNID_7','TP_UNID_15','TP_UNID_36','TP_UNID_61', 'res_MUNNOMEX', 'res_CAPITAL', 'res_SIGLA_UF'\n",
    "#    , 'evento_MUNNOMEX', 'evento_CAPITAL', 'evento_REGIAO', 'evento_SIGLA_UF', 'causabas_capitulo', 'causabas_categoria'\n",
    "#    , 'causabas_grupo', 'causabas_subcategoria'\n",
    "#]\n",
    "\n",
    "lista_missing_sinasc = [\n",
    "    'ESCMAE2010','SEMAGESTAC','PESO','IDADEMAE','sum_CENTROBS','sum_QTINST34','sum_QTINST35','sum_QTINST36','sum_QTINST37'\n",
    "    ,'sum_QTLEIT34','sum_QTLEIT38','sum_QTLEIT39','sum_QTLEIT40','sum_CENTRNEO','TP_UNID_5'\n",
    "    ,'TP_UNID_7','TP_UNID_15','TP_UNID_36','TP_UNID_61', 'GRAVIDEZ', 'res_MUNNOMEX', 'res_CAPITAL', 'res_SIGLA_UF'\n",
    "    , 'evento_MUNNOMEX', 'evento_CAPITAL', 'evento_REGIAO', 'evento_SIGLA_UF'\n",
    "]\n",
    "tam_antes = len(df_limpo)\n",
    "#df_limpo_sim = df_limpo_sim.dropna(subset = lista_missing_sim)\n",
    "df_limpo = df_limpo.dropna(subset = lista_missing_sinasc)\n",
    "df_limpo = df_limpo.reset_index(drop=True)\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove missing {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo missing SIM, somente nas colunas 'CNES'\n",
    "lista_missing_sim = [\n",
    "   'sum_CENTROBS','sum_QTINST34','sum_QTINST35','sum_QTINST36','sum_QTINST37','TP_UNID_5'\n",
    "    ,'TP_UNID_7','TP_UNID_15','TP_UNID_36','TP_UNID_61'\n",
    "]\n",
    "\n",
    "tam_sim = len(df_sim)\n",
    "df_sim = df_sim.dropna(subset = lista_missing_sim)\n",
    "df_sim = df_sim.reset_index(drop=True)\n",
    "tam_depois_sim = len(df_sim)\n",
    "print(f'Remove missing {tam_sim - tam_depois_sim} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ignored class SINASC\n",
    "tam_antes = len(df_limpo) \n",
    "df_limpo['evento_MUNNOMEX'] = df_limpo['evento_MUNNOMEX'].astype(str).fillna('IGNORADO')\n",
    "df_limpo = df_limpo.loc[~df_limpo['evento_MUNNOMEX'].str.contains('IGNORADO')]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored evento_MUNNOMEX {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[~df_limpo['res_MUNNOMEX'].str.contains('IGNORADO')]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored res_MUNNOMEX {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['idademae_faixa']!='Ignorado']\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored idademae_faixa {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['ESCMAE2010']!=9]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored ESCMAE2010 {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['GRAVIDEZ']!=9]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored GRAVIDEZ {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['idade_gestacao_faixa']!='Ignorado']\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored idade_gestacao_faixa {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['SEXO']!=0]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored SEXO {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['peso_faixa']!='Ignorado']\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored peso_faixa {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mother's age\n",
    "# Remover somente em SINASC\n",
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[(df_limpo['IDADEMAE']>=10) & (df_limpo['IDADEMAE']<=50)]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove IDADEMAE <10 or >50 {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight\n",
    "std_peso = np.std(df['PESO'])\n",
    "media_peso = np.mean(df['PESO'])\n",
    "lim_inf = media_peso - (6 * std_peso)\n",
    "lim_sup = media_peso + (6 * std_peso)\n",
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['PESO']>0]\n",
    "df_limpo = df_limpo.loc[(df_limpo['PESO']>=lim_inf) & (df_limpo['PESO']<=lim_sup)]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove PESO 6 std {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weeks of pregnancy less than 22 are not considered deaths, but rather miscarriages. SIM e SINASC\n",
    "df_limpo = pd.concat([df_limpo, df_sim])\n",
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['idade_gestacao_faixa']!='menor_22']\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove idade_gestacao_faixa menor_22 {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_depois = len(df)\n",
    "print(f'Total remove {tam_inicial - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = df_limpo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo[df_limpo['FLAG_BASE'] == 'SIM_DOFET'].value_counts(['ano_evento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo.to_csv('base_limpa/base_unificada_limpa_com_input.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
